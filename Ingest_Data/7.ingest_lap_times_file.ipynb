{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab8e4bf-6aa7-4612-9a5b-82853aa9eb0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Ingest lap_times folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35389840-0e7a-43cf-a9c1-2449d5d3756c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1 - Read the CSV file using the spark dataframe reader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135fa2d7-d299-4a55-b232-478d2ae6d85b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/common_functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14cb68a5-4471-491b-8042-bc7f76ce0018",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/configuration\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e5123dc-a7a4-4a90-8f38-c56f2ea48b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_data_source\", \"\")\n",
    "v_data_source = dbutils.widgets.get(\"p_data_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ee6d64-d883-4f80-ba69-1898c20e51e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_file_date\", \"2021-03-21\")\n",
    "v_file_date = dbutils.widgets.get(\"p_file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "019152b5-af6d-40d0-b4df-b35794dbde6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "lap_times_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n",
    "                                      StructField(\"driverId\", IntegerType(), True),\n",
    "                                      StructField(\"lap\", IntegerType(), True),\n",
    "                                      StructField(\"position\", IntegerType(), True),\n",
    "                                      StructField(\"time\", StringType(), True),\n",
    "                                      StructField(\"milliseconds\", IntegerType(), True)\n",
    "                                     ])\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af857d8-853c-40ba-adf3-d7b8a18f3a4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lap_times_df = spark.read \\\n",
    ".schema(lap_times_schema) \\\n",
    ".csv(f\"/mnt/avinashprojectformula1dl/raw/{v_file_date}/lap_times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a72e80-2540-433e-96b2-2950c0950149",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 2 - Rename columns and add new columns\n",
    "1. Rename driverId and raceId\n",
    "1. Add ingestion_date with current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d72f9a55-98b4-413f-9072-1aea6985e5ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lap_times_with_ingestion_date_df = add_ingestion_date(lap_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda542c1-e624-4d08-a821-2fca8022bc19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp ,lit\n",
    "final_df = lap_times_df.withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    ".withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    ".withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    ".withColumn(\"data_source\", lit(v_data_source)) \\\n",
    ".withColumn(\"file_date\", lit(v_file_date))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493fb0fe-275d-4225-9598-51fa0a0bd52a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3 - Write to output to processed container in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fcab535-a825-492e-807f-2dfd5131b01a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_condition = \"tgt.race_id = src.race_id AND tgt.driver_id = src.driver_id AND tgt.lap = src.lap AND tgt.race_id = src.race_id\"\n",
    "merge_delta_data(final_df, 'f1_processed', 'lap_times', processed_folder_path, merge_condition, 'race_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "336f2d50-3730-4a60-b8d1-aae30caffa4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#overwrite_partition(final_df, 'f1_processed', 'lap_times', 'race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d064c696-8031-47c8-8347-2816c5adbcc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7578ad1d-b413-4ae3-8896-9f550ec9c3f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#final_df.write.mode(\"overwrite\").formparquet(\"/mnt/avinashprojectformula1dl/processed/lap_times\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7.ingest_lap_times_file",
   "widgets": {
    "p_data_source": {
     "currentValue": "",
     "nuid": "77eec310-2803-4608-a421-0187326c77bf",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_data_source",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_file_date": {
     "currentValue": "2021-04-18",
     "nuid": "2e710147-8f6d-4efc-b870-e8f5e6d47be7",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2021-03-21",
      "label": null,
      "name": "p_file_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
