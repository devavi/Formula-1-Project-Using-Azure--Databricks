{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fc3f2be-9c68-4d7f-99f6-c46da8e55050",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1 - Read the JSON file using the spark dataframe reader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abce5f14-8252-4ad2-ab21-aa29f7634abe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/configuration\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e279f827-6845-481e-8652-6ffe52514d30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_data_source\", \"\")\n",
    "v_data_source = dbutils.widgets.get(\"p_data_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ed51c27-513e-471f-af05-b40a07f64f65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_file_date\", \"2021-03-21\")\n",
    "v_file_date = dbutils.widgets.get(\"p_file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bfc5498-1b66-4083-809f-3ef4ac034ee8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/common_functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a003f26-2fd8-4a57-a679-0b8356dcc02d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "qualifying_schema = StructType(fields=[StructField(\"qualifyId\", IntegerType(), False),\n",
    "                                      StructField(\"raceId\", IntegerType(), True),\n",
    "                                      StructField(\"driverId\", IntegerType(), True),\n",
    "                                      StructField(\"constructorId\", IntegerType(), True),\n",
    "                                      StructField(\"number\", IntegerType(), True),\n",
    "                                      StructField(\"position\", IntegerType(), True),\n",
    "                                      StructField(\"q1\", StringType(), True),\n",
    "                                      StructField(\"q2\", StringType(), True),\n",
    "                                      StructField(\"q3\", StringType(), True),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11e42815-0987-46e7-b12e-a4a676b92be2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "qualifying_df = spark.read \\\n",
    ".schema(qualifying_schema) \\\n",
    ".option(\"multiLine\", True) \\\n",
    ".json(f\"/mnt/avinashprojectformula1dl/raw/{v_file_date}/qualifying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651e8bf9-4182-47bc-8320-5696e49578e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2 - Rename columns and add new columns\n",
    "1. Rename qualifyingId, driverId, constructorId and raceId\n",
    "1. Add ingestion_date with current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c176aa3d-fc86-4970-9718-e133cc4f9b73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "qualifying_with_ingestion_date_df = add_ingestion_date(qualifying_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a3efe37-93af-4a33-baab-5a3264024ef3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp , lit\n",
    "final_df = qualifying_df.withColumnRenamed(\"qualifyId\", \"qualify_id\") \\\n",
    ".withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    ".withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    ".withColumnRenamed(\"constructorId\", \"constructor_id\") \\\n",
    ".withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    ".withColumn(\"data_source\", lit(v_data_source)) \\\n",
    ".withColumn(\"file_date\", lit(v_file_date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2a49fa-cb49-4b0d-9590-a8b1d2730ae8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3 - Write to output to processed container in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62a84472-8f4b-43cd-b7db-7ba75400c14b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_condition = \"tgt.qualify_id = src.qualify_id AND tgt.race_id = src.race_id\"\n",
    "merge_delta_data(final_df, 'f1_processed', 'qualifying', processed_folder_path, merge_condition, 'race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "664b49bb-143f-4f41-bc0b-4b975c231a39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#overwrite_partition(final_df, 'f1_processed', 'qualifying', 'race_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a940316-d8e5-4633-a829-674a4d2fed3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4407fe-a16f-4fc5-84cc-7be6fc7e936c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#final_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_processed.qualifying\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "8.ingest_qualifying_file",
   "widgets": {
    "p_data_source": {
     "currentValue": "",
     "nuid": "eaf11e48-edb1-4b7c-8d7f-65399e73ca4a",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_data_source",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "p_file_date": {
     "currentValue": "2021-04-18",
     "nuid": "129a4497-3a7f-4611-984e-856fee3d1bbc",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2021-03-21",
      "label": null,
      "name": "p_file_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
